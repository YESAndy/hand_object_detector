{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3acef5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# Tensorflow Faster R-CNN\n",
    "# Licensed under The MIT License [see LICENSE for details]\n",
    "# Written by Jiasen Lu, Jianwei Yang, based on code from Ross Girshick\n",
    "# --------------------------------------------------------\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import _init_paths\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import argparse\n",
    "import pprint\n",
    "import pdb\n",
    "import time\n",
    "import cv2\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F \n",
    "from PIL import Image\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dset\n",
    "# from scipy.misc import imread\n",
    "from roi_data_layer.roidb import combined_roidb\n",
    "from roi_data_layer.roibatchLoader import roibatchLoader\n",
    "from model.utils.config import cfg, cfg_from_file, cfg_from_list, get_output_dir\n",
    "from model.rpn.bbox_transform import clip_boxes\n",
    "# from model.nms.nms_wrapper import nms\n",
    "from model.roi_layers import nms\n",
    "from model.rpn.bbox_transform import bbox_transform_inv\n",
    "from model.utils.net_utils import save_net, load_net, vis_detections, vis_detections_PIL, vis_detections_filtered_objects_PIL, vis_detections_filtered_objects # (1) here add a function to viz\n",
    "from model.utils.blob import im_list_to_blob\n",
    "from model.faster_rcnn.vgg16 import vgg16\n",
    "from model.faster_rcnn.resnet import resnet\n",
    "import pdb\n",
    "\n",
    "from inference import inference, get_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cd8cfef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load checkpoint models/res101_handobj_100K/pascal_voc/faster_rcnn_1_8_132028.pth\n",
      "load model successfully!\n"
     ]
    }
   ],
   "source": [
    "image_file = \"./images/ezgif-frame-085.png\"\n",
    "\n",
    "img = cv2.imread(image_file)\n",
    "model = get_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a03d6f6d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pascal_classes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m obj_dets, hand_dets \u001b[38;5;241m=\u001b[39m \u001b[43minference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(obj_dets, hand_dets)\n",
      "File \u001b[0;32m~/research/2023/GIRL/scripts/hand_object_detector/inference.py:324\u001b[0m, in \u001b[0;36minference\u001b[0;34m(im, fasterRCNN)\u001b[0m\n\u001b[1;32m    321\u001b[0m       \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    322\u001b[0m           box_deltas \u001b[38;5;241m=\u001b[39m box_deltas\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m4\u001b[39m) \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mFloatTensor(cfg\u001b[38;5;241m.\u001b[39mTRAIN\u001b[38;5;241m.\u001b[39mBBOX_NORMALIZE_STDS) \\\n\u001b[1;32m    323\u001b[0m                     \u001b[38;5;241m+\u001b[39m torch\u001b[38;5;241m.\u001b[39mFloatTensor(cfg\u001b[38;5;241m.\u001b[39mTRAIN\u001b[38;5;241m.\u001b[39mBBOX_NORMALIZE_MEANS)\n\u001b[0;32m--> 324\u001b[0m       box_deltas \u001b[38;5;241m=\u001b[39m box_deltas\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m4\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[43mpascal_classes\u001b[49m))\n\u001b[1;32m    326\u001b[0m pred_boxes \u001b[38;5;241m=\u001b[39m bbox_transform_inv(boxes, box_deltas, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    327\u001b[0m pred_boxes \u001b[38;5;241m=\u001b[39m clip_boxes(pred_boxes, im_info\u001b[38;5;241m.\u001b[39mdata, \u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pascal_classes' is not defined"
     ]
    }
   ],
   "source": [
    "obj_dets, hand_dets = inference(img, model)\n",
    "print(obj_dets, hand_dets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e5c465",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "girl",
   "language": "python",
   "name": "girl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
